{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "future-charge",
   "metadata": {},
   "source": [
    "# Explorative Datenanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-wonder",
   "metadata": {},
   "source": [
    "## count_words-Funktion für Frequency-DataFrames\n",
    "Folgende Funktion erzeugt einen DataFrame mit den Worthäufigkeiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "clean-sacramento",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:18:14.988946Z",
     "start_time": "2021-05-03T19:18:14.982082Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_words(df, column='tokens', preprocess=None, min_freq=2):\n",
    "\n",
    "    # process tokens and update counter\n",
    "    def update(doc):\n",
    "        tokens = doc if preprocess is None else preprocess(doc)\n",
    "        counter.update(tokens)\n",
    "\n",
    "    # create counter and run through all data\n",
    "    counter = Counter()\n",
    "    df[column].progress_map(update)\n",
    "\n",
    "    # transform counter into data frame\n",
    "    freq_df = pd.DataFrame.from_dict(counter, orient='index', columns=['freq'])\n",
    "    freq_df = freq_df.query('freq >= @min_freq')\n",
    "    freq_df.index.name = 'token'\n",
    "    \n",
    "    return freq_df.sort_values('freq', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-amplifier",
   "metadata": {},
   "source": [
    "## wordcloud-Funktion für die Visualisierung häufiger Wörter\n",
    "Folgende Funktion erzeugt eine Wordcloud mittels des entsprechenden Pythoh-Moduls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "generic-impact",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:18:15.148441Z",
     "start_time": "2021-05-03T19:18:15.000066Z"
    }
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "\n",
    "def wordcloud(word_freq, title=None, max_words=200, stopwords=None):\n",
    "\n",
    "    wc = WordCloud(width=800, height=400, \n",
    "                   background_color= \"black\", colormap=\"Paired\", \n",
    "                   max_font_size=150, max_words=max_words)\n",
    "    \n",
    "    # convert data frame into dict\n",
    "    if type(word_freq) == pd.Series:\n",
    "        counter = Counter(word_freq.fillna(0).to_dict())\n",
    "    else:\n",
    "        counter = word_freq\n",
    "\n",
    "    # filter stop words in frequency counter\n",
    "    if stopwords is not None:\n",
    "        counter = {token:freq for (token, freq) in counter.items() \n",
    "                              if token not in stopwords}\n",
    "    wc.generate_from_frequencies(counter)\n",
    " \n",
    "    plt.title(title) \n",
    "\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-applicant",
   "metadata": {},
   "source": [
    "## compute_idf-Funktion zur Gewichtung der Worte mittels TF-IDF\n",
    "Funktion gewichtet die Wörter in einem DataFrame mittels TF-IDF-Gewichtung. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "completed-expansion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:18:15.156186Z",
     "start_time": "2021-05-03T19:18:15.150451Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_idf(df, column='tokens', preprocess=None, min_df=2):\n",
    "\n",
    "    def update(doc):\n",
    "        tokens = doc if preprocess is None else preprocess(doc)\n",
    "        counter.update(set(tokens))\n",
    "\n",
    "    # count tokens\n",
    "    counter = Counter()\n",
    "    df[column].progress_map(update)\n",
    "\n",
    "    # create data frame and compute idf\n",
    "    idf_df = pd.DataFrame.from_dict(counter, orient='index', columns=['df'])\n",
    "    idf_df = idf_df.query('df >= @min_df')\n",
    "    idf_df['idf'] = np.log(len(df)/idf_df['df'])+0.1\n",
    "    idf_df.index.name = 'token'\n",
    "    return idf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-offset",
   "metadata": {},
   "source": [
    "## kwic-Funktion für Kontextanalyse\n",
    "Funktion analysiert den Kontext der Schlagwörter und gibt diesen aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "employed-trail",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:18:16.119857Z",
     "start_time": "2021-05-03T19:18:15.161085Z"
    }
   },
   "outputs": [],
   "source": [
    "from textacy.text_utils import KWIC\n",
    "\n",
    "def kwic(doc_series, keyword, window=35, print_samples=5):\n",
    "\n",
    "    def add_kwic(text):\n",
    "        kwic_list.extend(KWIC(text, keyword, ignore_case=True, \n",
    "                              window_width=window, print_only=False))\n",
    "\n",
    "    kwic_list = []\n",
    "    doc_series.progress_map(add_kwic)\n",
    "\n",
    "    if print_samples is None or print_samples==0:\n",
    "        return kwic_list\n",
    "    else:\n",
    "        k = min(print_samples, len(kwic_list))\n",
    "        print(f\"{k} random samples out of {len(kwic_list)} \" + \\\n",
    "              f\"contexts for '{keyword}':\")\n",
    "        for sample in random.sample(list(kwic_list), k):\n",
    "            print(re.sub(r'[\\n\\t]', ' ', sample[0])+'  '+ \\\n",
    "                  sample[1]+'  '+\\\n",
    "                  re.sub(r'[\\n\\t]', ' ', sample[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-rainbow",
   "metadata": {},
   "source": [
    "## Worthäufigkeiten pro Zeit oder Kategorie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-penalty",
   "metadata": {},
   "source": [
    "### count_keywords-Funktion \n",
    "Funktion zählt die gegebenen Schlagwörter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "empirical-prague",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:18:16.125611Z",
     "start_time": "2021-05-03T19:18:16.121917Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_keywords(tokens, keywords, unique=False): \n",
    "    tokens = [t for t in tokens if t in keywords]\n",
    "    if unique:\n",
    "        tokens = set(tokens)\n",
    "    counter = Counter(tokens)\n",
    "    return [counter.get(k, 0) for k in keywords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-seller",
   "metadata": {},
   "source": [
    "### count_keywords_by-Funktion\n",
    "Funktion zählt die Schlagwörter anhand eines gewissen Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "official-mountain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T19:18:16.130620Z",
     "start_time": "2021-05-03T19:18:16.127397Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_keywords_by(df, by, keywords, column='tokens'):\n",
    "    \n",
    "    df = df.reset_index(drop=True) # if the supplied dataframe has gaps in the index\n",
    "    freq_matrix = df[column].progress_apply(count_keywords, keywords=keywords)\n",
    "    freq_df = pd.DataFrame.from_records(freq_matrix, columns=keywords)\n",
    "    freq_df[by] = df[by] # copy the grouping column(s)\n",
    "    \n",
    "    return freq_df.groupby(by=by).sum().sort_values(by)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
